{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 순서\n",
    "1. 필요한 라이브러리 설치 (없다고 하는건 알아서 설치바람)\n",
    "2. 순서대로 2번째까지는 한번만 실행하면 된다.\n",
    "3. 3 ~ 5번 코드 블록은 연결 끊길때마다 인덱스를 바꿔가면서 반복 실행하면 된다. (확인용 코드는 귀찮으면 안해도 ㄱㅊ)\n",
    "4. 끊길 때마다 지금까지 크롤링 된 데이터를 저장해야 함. -> 저장 양식 지켜서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: C:\\Users\\SSAFY\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ssafy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from BeautifulSoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "# 1번 블록\n",
    "pip install BeautifulSoup4\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번 블록\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "def get_rate(detail_info):\n",
    "    rate_list = [0,0,0]\n",
    "    try:\n",
    "        rates = detail_info[0].find_all('div', attrs={'class' : 'jw-scoring-listing__rating'})\n",
    "        for rate in rates:\n",
    "            r = rate.a.get_text()\n",
    "            r = r.rstrip()\n",
    "            if r[-1] == '%':\n",
    "                r = int(r[:-1])\n",
    "                rate_list[0] = r\n",
    "            else:\n",
    "                if r[-1] == ')':  # popularity가 있다면\n",
    "                    r, popularity = r.split('(')\n",
    "                    popularity = popularity[:-1]\n",
    "                    p = int(popularity[:-1])\n",
    "                    if popularity[-1] == 'k':\n",
    "                        p *= 10**3\n",
    "                    elif popularity[-1] == 'm':\n",
    "                        p *= 10**6\n",
    "                    rate_list[2] = p           \n",
    "                r = float(r.rstrip())\n",
    "                # print(r)\n",
    "                rate_list[1] = r\n",
    "    except:\n",
    "        rate_list = None\n",
    "    # print('rate_list : ', rate_list)\n",
    "    return rate_list\n",
    "\n",
    "def get_genre(detail_info):\n",
    "    try:\n",
    "        genres = detail_info[1].find('div', attrs={'class' : 'detail-infos__value'}).get_text()\n",
    "        genre_list = list(genres.split(','))\n",
    "        for i in range(len(genre_list)):\n",
    "            genre_list[i] = genre_list[i].strip()\n",
    "        # print('genre : ',genre_list)\n",
    "    except:\n",
    "        genre_list = None\n",
    "    return genre_list\n",
    "\n",
    "def get_run_time(detail_info):\n",
    "    run_time = 0\n",
    "    try:\n",
    "        run_times = detail_info[2].find('div', attrs={'class' : 'detail-infos__value'}).get_text()\n",
    "        run_time_list = run_times.split(' ')\n",
    "        for run in run_time_list:\n",
    "            if 'min' in run:\n",
    "                run_time += int(run[:-3])\n",
    "            elif '분' in run:\n",
    "                run_time += int(run[:-1])\n",
    "            \n",
    "            if 'hr' in run:\n",
    "                run_time += int(run[:-2])*60\n",
    "            elif '시간' in run:\n",
    "                run_time += int(run[:-2])*60\n",
    "\n",
    "        # print('run_time : ',run_time)\n",
    "    except:\n",
    "        run_time = None\n",
    "    return run_time\n",
    "\n",
    "def get_content_rating(detail_info):\n",
    "    try:\n",
    "        content_rating = detail_info[3].find('div', attrs={'class' : 'detail-infos__value'}).get_text()\n",
    "        content_rating = int(content_rating)\n",
    "    except:\n",
    "        content_rating = None\n",
    "    # print('content_rating : ',content_rating)\n",
    "    return content_rating\n",
    "\n",
    "def get_title(title_block):\n",
    "    try:\n",
    "        block = title_block.h1.get_text().rstrip()\n",
    "        title, season_info = block.split('-')\n",
    "        seasons = season_info.split(' ')\n",
    "        title = title.rstrip()\n",
    "        season = int(seasons[-1])\n",
    "        # print('season :',season)\n",
    "    except:\n",
    "        title = title_block.h1.get_text().strip()\n",
    "        season = None\n",
    "\n",
    "    return title, season\n",
    "\n",
    "def get_links(ott_box):\n",
    "    result = []\n",
    "    link = ott_box.a.get('href')\n",
    "    # for link in links:\n",
    "    # print(link)\n",
    "    # link = str(link)\n",
    "    a = link[32:]\n",
    "    # print('a :',a)\n",
    "    b = a.split('&')[0]\n",
    "    print('b :', b)\n",
    "    if 'netflix' in b or 'wavve' in b or 'watcha' in b or 'disney-plus' in b:\n",
    "        ott_url = urllib.parse.unquote(b)\n",
    "        result.append(ott_url)\n",
    "    print('ott 링크 ?? ',result)\n",
    "    return result\n",
    "\n",
    "def get_otts(ott_box):\n",
    "    print(f'================= ott 이름 찾기')\n",
    "    otts = []\n",
    "    ott = ott_box.find('picture', attrs={'class' : 'provider-icon'})\n",
    "    # print(ott_lists)\n",
    "    # for ott in ott_lists:\n",
    "    name = ott.img['alt']\n",
    "    print('ott 이름 : ',name)\n",
    "    if name in ('Watcha', 'Netflix', 'wavve', 'Disney Plus'):\n",
    "        otts.append(name)\n",
    "    print('ott 확인 :', otts)\n",
    "    return otts\n",
    "\n",
    "def crawling(link):\n",
    "    webpage = requests.get(link)\n",
    "    soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "\n",
    "    picture = soup.find('picture', attrs={'class': 'picture-comp title-poster__image'})\n",
    "    try:\n",
    "        image = picture.img['data-src']\n",
    "    except:\n",
    "        image = None\n",
    "    # print('image : ',image)\n",
    "    backdrops = soup.find('picture', attrs={'class': 'picture-comp'})\n",
    "    try:\n",
    "        backdrop = backdrops.img['src']\n",
    "    except:\n",
    "        backdrop = None\n",
    "    # print('backdrop :', backdrop)\n",
    "\n",
    "    # 컨텐츠 정보 - 평점, 장르, 러닝타임, 연령등급\n",
    "    detail_info = soup.find_all('div', attrs={'class': 'detail-infos'})\n",
    "    rate_list = get_rate(detail_info)\n",
    "    genre_list = get_genre(detail_info)\n",
    "    run_time = get_run_time(detail_info)\n",
    "    content_rating = get_content_rating(detail_info)\n",
    "\n",
    "    # 제목, 개봉연도\n",
    "    title_block = soup.find('div', attrs={'class': 'title-block'})\n",
    "    title, season = get_title(title_block)\n",
    "    release_date = title_block.span.get_text().strip()\n",
    "    release_date = int(release_date[1:-1])\n",
    "    # print('release_date',release_date)\n",
    "\n",
    "    # ott 링크\n",
    "    ott_box = soup.find('div', attrs={'class': 'price-comparison__grid__row__holder'})\n",
    "    ott_links = get_links(ott_box)\n",
    "    otts = get_otts(ott_box)\n",
    "    \n",
    "    # 에피소드 개수\n",
    "    content = soup.find('div', attrs={'class' : 'jw-info-box__container-content'})\n",
    "    contents = content.find_all('h2', attrs={'class': 'detail-infos__subheading--label'})\n",
    "    episode_cnt = None\n",
    "    for h2 in contents[2:4]:\n",
    "        subtitle = h2.get_text().rstrip()\n",
    "        # print(subtitle)\n",
    "        if subtitle[-1:] == '화':\n",
    "            try:\n",
    "                episode_cnt = int(subtitle[:-1])\n",
    "                break\n",
    "            except:\n",
    "                episode_cnt = None\n",
    "            # print('episode_cnt : ',episode_cnt)\n",
    "\n",
    "    # 줄거리\n",
    "    try:\n",
    "        Synopsis = soup.find('p', attrs={'class' : 'text-wrap-pre-line mt-0'}).span.get_text()\n",
    "    except:\n",
    "        Synopsis = None\n",
    "        \n",
    "    # info = [title, release_date, rate_list, genre_list, run_time, content_rating]\n",
    "    return title, season, release_date, rate_list, genre_list, run_time, content_rating, episode_cnt, Synopsis, image, backdrop, ott_links, otts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 할당량\n",
    "### 끊긴 시점부터 시작 인덱스만 바꿔주세용\n",
    "**!!!!!!마지막으로 print된 인덱스부터 시작!!!!!**\n",
    "- 병진 : netflix [0:4000]\n",
    "- 준형 : watcha [0:4000]\n",
    "- 은성 : wavve [0:4000]\n",
    "- 용찬 : watcha [4000:]\n",
    "- 민혁 : wavve [4000:8000]\n",
    "- 성은 : netflix [4000:] + wavve [8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================= 1999 ==============================================\n",
      "======================== 단일 컨텐츠\n",
      "b : http%3A%2F%2Fwww.netflix.com%2Ftitle%2F81425050\n",
      "ott 링크 ??  ['http://www.netflix.com/title/81425050']\n",
      "================= ott 이름 찾기\n",
      "ott 이름 :  Netflix\n",
      "ott 확인 : ['Netflix']\n",
      "결과 :  디보션 None 2022 [79, 6.6, 19000] ['전쟁', '액션', '드라마'] 139 None None 미 해군 최초의 흑인 파일럿 제시 브라운. 한국 전쟁에서 위험을 무릅쓴 비행에 나선다. 그리고 그의 곁에는 생사를 함께하는 윙맨 톰 허드너가 있다. https://images.justwatch.com/poster/304841860/s592/devotion https://www.justwatch.com/images/backdrop/302276499/s1440/devotion ['http://www.netflix.com/title/81425050'] ['Netflix']\n",
      "============================================= 2000 ==============================================\n",
      "======================== 단일 컨텐츠\n",
      "b : http%3A%2F%2Fwww.netflix.com%2Ftitle%2F70020509\n",
      "ott 링크 ??  ['http://www.netflix.com/title/70020509']\n",
      "================= ott 이름 찾기\n",
      "ott 이름 :  Netflix\n",
      "ott 확인 : ['Netflix']\n",
      "결과 :  히트 None 1995 [89, 8.3, 670000] ['드라마', '스릴러', '범죄', '액션'] 171 None None 닐 맥컬리(로버트 드 니로)는 빈틈없고 치밀하게 일을 처리하는 프로 범죄자지만 따뜻한 가정의 온기를 동경한다. 반면 LA 경찰국 강력계 수사반장인 빈센트 한나(알 파치노)는 두 번의 이혼 경력에 이어 세 번째 결혼마저 위기를 맞은 불안정한 사생활의 소유자지만, 일에 있어서는 굶주린 짐승처럼 집요하게 쫓아가 결국에는 해결을 보고 만다. 닐과 그의 동료들이 특급우편 발송 차량을 습격하는 대규모 도난 사건을 일으켜 증권 투자사 간부의 고액 채권을 강탈한다. 사건 발생 직후부터 빈센트는 예리한 추리력으로 한걸음씩 닐에게 접근해간다. 닐 역시 빈센트의 추격을 눈치채는데... https://images.justwatch.com/poster/123329294/s592/heat https://www.justwatch.com/images/backdrop/8655235/s1440/heat ['http://www.netflix.com/title/70020509'] ['Netflix']\n",
      "============================================= 2001 ==============================================\n",
      "======================= 시즌제 컨텐츠\n",
      "b : https%3A%2F%2Fwww.crunchyroll.com%2Fwatch%2FGQJUG2PM1%2Fthe-witch-and-the-bride\n",
      "ott 링크 ??  []\n",
      "================= ott 이름 찾기\n",
      "ott 이름 :  Crunchyroll\n",
      "ott 확인 : []\n",
      "결과 :  기동전사 건담: 수성의 마녀 1 2022 [86, 7.7, 0] ['SF', '액션', '드라마', '애니메이션'] 24 15 20 수많은 기업이 우주로 진출해 거대한 경제권을 구축한 시대. 모빌슈트 산업을 선도하는 기업, ‘베네리트 그룹’이 운영하는 ‘아스티카시아 고등 전문 학원’에 변두리 행성인 수성에서 한 소녀가 편입해 온다. 소녀의 이름은 슬레타 머큐리. 순진무구한 마음에 밝은 빛을 품고 소녀는 새로운 세상에 걸음을 내디딘다. https://images.justwatch.com/poster/301262480/s592/시즌-1 https://www.justwatch.com/images/backdrop/289201464/s1440/시즌-1 [] []\n"
     ]
    }
   ],
   "source": [
    "# 3번 블록\n",
    "# justwatch에서 자주 연결을 끊기 때문에 print 된 마지막 index부터 다시 시작하면 됩니다!\n",
    "import csv\n",
    "\n",
    "file = open('./dataset/links.csv', 'r', encoding='utf-8')\n",
    "URLs = csv.reader(file)\n",
    "URLs = list(URLs)\n",
    "title = []\n",
    "season = []\n",
    "release_date = []\n",
    "rate_jw = []\n",
    "rate_imdb = []\n",
    "popularity = []\n",
    "genres = []\n",
    "run_time = []\n",
    "content_rating = []\n",
    "episode_cnt = []\n",
    "Synopsis = []\n",
    "images = []\n",
    "backdrops = []\n",
    "otts = []\n",
    "links = []\n",
    "for index, url in URLs[2000:2003]:  # 이전 마지막 index부터 다시 크롤링 시작 (!!!!!!마지막으로 print된 인덱스부터!!!!!)\n",
    "    print(f'============================================= {index} ==============================================') # 이걸로 마지막 인덱스 파악 ㄱㄱ\n",
    "    webpage = requests.get(url)\n",
    "    soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "    content = soup.find('div', attrs={'class' : 'jw-info-box__container-content'})\n",
    "    contents = content.find_all('h2', attrs={'class': 'detail-infos__subheading--label'})\n",
    "    subtitle_list = []\n",
    "    season_cnt = 0\n",
    "    for h2 in contents:\n",
    "        subtitle = h2.get_text().rstrip()\n",
    "        # print(subtitle)\n",
    "        if '시즌' in subtitle:\n",
    "            # print(subtitle[:-4])\n",
    "            season_cnt = int(subtitle[:-4]) \n",
    "            # print('season_cnt : ',season_cnt)\n",
    "            break\n",
    "        subtitle_list.append(h2.get_text())\n",
    "\n",
    "    if season_cnt > 0:\n",
    "        print('======================= 시즌제 컨텐츠')\n",
    "        num = 1\n",
    "        while num < season_cnt + 1:\n",
    "            try:\n",
    "                link = url + f'/시즌-{num}'\n",
    "                # print(link)\n",
    "                t, ss, release, rate_list, genre_list, run, rating, episode, Syno, img, backdrop, ott, link = crawling(link)\n",
    "                print('결과 : ',t, ss, release, rate_list, genre_list, run, rating, episode, Syno, img, backdrop, ott, link)\n",
    "                title.append(t)\n",
    "                season.append(ss)\n",
    "                release_date.append(release)        \n",
    "                rate_jw.append(rate_list[0])\n",
    "                rate_imdb.append(rate_list[1])\n",
    "                popularity.append(rate_list[2])\n",
    "                genres.append(genre_list)\n",
    "                run_time.append(run)\n",
    "                content_rating.append(rating)\n",
    "                episode_cnt.append(episode)\n",
    "                Synopsis.append(Syno)\n",
    "                images.append(img)\n",
    "                backdrops.append(backdrop)\n",
    "                otts.append(ott)\n",
    "                links.append(link)\n",
    "                num += 1\n",
    "            except:\n",
    "                break\n",
    "    else:\n",
    "        print('======================== 단일 컨텐츠')\n",
    "        t, ss, release, rate_list, genre_list, run, rating, episode, Syno, img, backdrop, ott, link = crawling(url)\n",
    "        print('결과 : ',t, ss, release, rate_list, genre_list, run, rating, episode, Syno, img, backdrop, ott, link)\n",
    "        title.append(t)\n",
    "        season.append(ss)\n",
    "        release_date.append(release)\n",
    "        rate_jw.append(rate_list[0])\n",
    "        rate_imdb.append(rate_list[1])\n",
    "        popularity.append(rate_list[2])\n",
    "        genres.append(genre_list)\n",
    "        run_time.append(run)\n",
    "        content_rating.append(rating)\n",
    "        episode_cnt.append(episode)\n",
    "        Synopsis.append(Syno)\n",
    "        images.append(img)\n",
    "        backdrops.append(backdrop)\n",
    "        otts.append(ott)\n",
    "        links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4번 블록 (확인용)\n",
    "for info in zip(title,season, release_date,rate_jw,rate_imdb,popularity,genres,run_time,content_rating ,episode_cnt,Synopsis,images,backdrops):\n",
    "    print(info)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장하기 전\n",
    "현재 위치 (이 파일을 저장하고 실행한 위치)에 dataset이라는 폴더를 만드새용 (1번만 하면 됨!)\n",
    "만들기만 하고 아래 5번 블록 실행하면 됨 good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5번 블록\n",
    "# csv 파일로 저장하는 코드 \n",
    "# ***** 필수 *****\n",
    "# 현재 실행 위치(이 크롤링 파일 저장한 위치)에 dataset 폴더 만들고 시작하기\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "savePath = os.getcwd() +'\\\\dataset'\n",
    "\n",
    "df = pd.DataFrame({\"title\": title, \"season\": season, \"release_date\": release_date, \"rate_jw\": rate_jw, \"rate_imdb\": rate_imdb, \"popularity\": popularity, \"genres\": genres, \"run_time\": run_time, \"content_rating\": content_rating , \"episode_cnt\": episode_cnt, \"Synopsis\": Synopsis, \"images\": images, \"backdrops\": backdrops})\n",
    "\n",
    "# 본인이 맡은 파트의 ott 이름 + 시작 index + 끝 index 형식으로 파일 저장\n",
    "df.to_csv(savePath+\"\\\\wavve_10273_end.csv\", index=True, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
